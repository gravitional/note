# 两小时入门MPI与并行计算系列

[MPI 教程介绍](https://mpitutorial.com/tutorials/mpi-introduction/zh_cn/) [入门MPI与并行计
算系列](https://zhuanlan.zhihu.com/p/355652501)

## 本教程的使用方法

你只需要会C和C++或Fortran, 掌握Linux的基本操作以及一定的计算机软硬件常识, 即可学习本文. 除
此之外, 你还需要有一个能上手练习的环境. 具备了以上条件, 你就可以开始对本文的学习了.  本文
的目标是希望初学者在阅读和学习之后, 能达到对MPI和并行计算有基本的了解. 并且在此之后, 可以
逐渐变得更容易理解有关MPI的专业书籍.

在学习本教程时, 强烈建议结合都志辉编著的<高性能计算之并行编程技术 —— MPI并行程序设计>作为
本文的延伸阅读材料.本教程从都志辉编著的该书中借鉴了一部分代码和图片用于讲解.学习MPI的过程
中, 少不了反复的练习和实践. 因此, 每一章节所讲的代码都有必要亲自动手实践一遍.如果时间允许,
我之后还会更新一章用于练习的题目.

## 并行计算预备知识

### 为什么要并行计算?

计算机界有一个著名的定律叫摩尔定律, 是由Intel创始人之一戈登摩尔所提出的.他说, 集成电路上可
容纳的元器件的数目, 约每隔18-24个月便会增加一倍, 性能也将提升一倍.然而, 晶体管的数量增加,
功耗和产生的热量也随之大幅增加.当散热能力近乎达到极限时, 通过增加单个CPU的性能来换取更高的
运算性能已不可取.考虑到物理极限的约束和设计更复杂的架构所产生的高额成本等因素, 开始朝向多
核的方向发展.

### 如何实现并行计算?

将一个计算任务分配到多个节点上去计算, 通常有两种方式. 一个是任务并行, 一个数据并行. 顾名思
义, 任务并行就是每个节点执行不同的任务, 而数据并行就是每个节点存储不同的数据. 因为本系列教
程的重点是MPI, 因此从程序这一划分粒度来分类, 可分为SPMD(单程序多数据)并行和MPMD(多程序多数
据并行).

SPMD即为多个计算集群都运行同一个程序, 然而他们各自的存储是独立的. 比如进程0和进程1分别有一
个数组A,这两个数组可以分别为[0,2,3]和[1,2,3]. 当执行一个程序, 要求计算A=A+1时, 进程0和进程
1会同时用各自的数组A去执行相同的程序, 得到的结果分别为 `[1,3,4]` 和 `[2,3,4]`. 所以, 在这
种情况下, 如果想对某一进程执行特殊于其他进程的操作, 可以加一个if(process_id==0)的语句,从而
让进程1不进入该if语句中去. MPMD则相当于各自进程执行各自的程序. SPMD和MPMD的表达能力是相同
的, 只是针对不同的问题编写难易而已. MPI是可以写SPMD和MPMD的并行程序的. 之所以这么设计, 是
由并行计算机的体系结构所决定的, 因此有必要简单描述一下计算机的运作方式.

当前的计算机采用冯诺依曼体系结构, CPU执行的指令和参与计算所用到的数据都存储于内存(该内存指
的是存储设备, 不单指内存条)当中, 而CPU会按照程序顺序执行. 众所周知, 内存是线性存储的. 即假
一个内存有256个存储空间, 则这256个存储空间的地址会依次对应于0-255. 因此, 将CPU设计成多个核
心时, 需要解决存储问题.

在设计并行计算机时, 最直接的方式就是多个计算单元共享一个内存, 即如下图所示. 共享内存的编程
在数据交换和访问上有较大的优势, 程序编写起来更加简单. 但在扩展性上有较大的瓶颈. 另一种方式
为, 分布式内存. 即每个计算单元有单独的内存, 计算单元之间的数据访问通过互联网络去传输. 这一
架构在可移植性和扩展上会强很多, 但消息的传递会成为程序设计中的难点. 将这两点结合, 即是分布
式共享内存并行计算机的架构, 也是当今最常用的体系结构. 之后的MPI编程中, 将会涉及很多消息通
信, 之后的学习会加深对此的理解.

![共享内存与分布式内
存](https://pic3.zhimg.com/80/v2-e6adab674bf0060626f9fdbe5b09c2ca_720w.jpg)

### 改写一个简单的串行程序

前半部分讲了基本理论, 接下来通过分析一个串行程序和一个并行程序, 来讲解MPI是如何实现上述理
论过程的.

我们不妨举一个简单的例子, 假设A是一个2×4的矩阵, 想对矩阵A进行求和. 如果是串行程序, 那么需
要写两层循环.

```cpp
int sum=0;
for(int i=0;i<2;i++)
{
    for(int j=0;j<4;j++)
    {
        sum=sum+A[i][j];
    }
}
```

如果我们想使用2个进程去做并行计算, 这两个进程分别做第一行和第二行的求和, 然后再将这两个数
去求和. MPI_SEND和MPI_RECV这两个函数分别为发送和接收, 具体的将在之后一章讲解.

本代码只是用于讲解MPI如何实现数据通信, 真正的并行程序是不会这么写的, 在之后的章节会介绍对
等模式和主从模式. 在用MPI进行计算时, 消息通信的时间成本是比较大的, 所以通常会采用重复计算
来避免不必要的通信, 使总运行时间变短. 在具体优化代码时, 是需要分析通信时间和计算时间, 使其
达到一个最优平衡. 不过, 下面这个程序可以看出MPI程序的基本写法和几个基本操作.

初学者可能会受到串行程序的思维惯性. 为了便于理解, 可以把下面这个程序理解成是在两个独立的进
程上运行, 不仅计算独立, 存储也独立. 而这俩cpu的标识要通过myid这个变量来获取. 存储独立代表
着这两个变量A只有变量名相同, 存储的数据内容地址是不同的. 从下面代码可以看出, 两个进程分别
对不同的数组A和变量s在执行相同的代码. 为了让两个进程做不同的操作, 就需要加上if语句, 当myid
是0的时候自然就不会执行else if语句里的内容了, 反之同理. 在两个进程分别做完各自的操作之后,
需要一个进程把数据发送给另一个进程, 这样才能将结果汇总起来. 进程与进程之间在实际上是平等关
系. 但是可以在逻辑上, 规定比如进程0是主进程, 涉及到分发和接受时赋予进程0以特殊的逻辑地位,
这就是后面要讲的并行程序的主从模式. 除此之外还有对等模式, 后文会专题去讲.

```cpp
MPI_Init(&argc,&argv);
MPI_Comm_rank(MPI_COMM_WORLD,&myid);        //得到的变量myid即为当前的进程号
//假设要求和的矩阵为A={[1,1,1,1],[2,2,2,2]}
if(myid==0)
{
    memset(A,1,sizeof(int)); //将数组A全赋值为1
}
else if (myid==1)
{
    memset(A,2,sizeof(int)); //将数组A全赋值为2
}
//以上部分是将数组的两行分别存储到进程0和进程1上
for(int i=0;i<4;i++)
{
    s=s+A[i];
}
if(myid==1)
{
    MPI_Send(s,1,MPI_INT,0,99,MPI_COMM_WORLD);
//将求和结果s发送到进程0
}
if(myid==0)
{
    MPI_Recv(s1,1,MPI_INT,1,99,MPI_COMM_WORLD,&status);
//用s1这个变量来存储从进程1发送来的求和结果
    s=s+s1;
}
printf("%d",&s);
MPI_Finalize();
```

上述代码如果看不明白也没关系, 之后将一步一步讲解如何用Fortran和C++写一个MPI程序的全部过程.

> 参考资料; 都志辉. 高性能计算并行编程技术:MPI并行程序设计[M]. 清华大学出版社, 2001.

## MPI的安装与配置

### MPI与OpenMPI和MPICH等的关系

MPI(Message Passing Interface), 由其字面意思也可些许看出, 是一个信息传递接口. 可以理解为是
一种独立于语言的信息传递标准. 而OpenMPI和MPICH等是对这种标准的具体实现. 也就是说, OpenMPI
和MPICH这类库是具体用代码实现浏MPI标准. 因此我们需要安装OpenMPI或者MPICH去实现我们所学的
MPI的信息传递标准.

为了考虑到教程的完整性, 所以单独用一篇文章来介绍一下MPI库的安装方法. 安装方法千篇一律, 网
上随手一查就能查到一堆, 我本人也写不出什么花样来. 若你已经配置好了MPI环境, 可以忽略本文,
直接跳到下一章去学习. 考虑到大部分人在实现并行编程都是在CPU集群上完成, 而这些服务器几乎都
是使用的Linux系统. 因此下文采用Linux来作为讲解, 为了使本文看起来稍微有点干货, 我尽量在安装
步骤中扩展一些我认为Linux初学者有必要知道的东西. 相信初学者在用集群安装时会出现各种各样的
问题, 报一些对于初学者来说难以解决的问题. 这对于初学者来说很打击积极性, 如果学习的热情被安
装时的报错信息消耗殆尽是很可惜的. 各位在用集群安装时, 因为没有root权限, 可能会出现各种各样
比如编译器过老, 管理员安装的编译器路径地址不知道等问题, 这些可能初学者难以解决. 用虚拟机学
习MPI的学习者可能就会好一些, 因为有root权限, 所需要的环境都可以自己装. 初学者如果遇到安装
时的报错解决不了的话, 也可以私信或者评论区留言.

MPICH和OpenMPI等是采用MPI标准的通信协议. 本文将选择MPICH的安装作为示范, 
一步一步讲解如何配置MPI的环境.  OpenMPI的按照方法也同理.

### MPI的下载与安装

在开始安装之前, 先检查一下是否已经安装好了相应的编译器.

which gcc which gfortran

当显示了gcc和gfortran的路径, 即可进行下一步的安装, 若没有相应的编译器, 请先安装编译器.  如
何安装编译器可以自行使用搜索引擎查询. 在linux中, which是用来查询环境变量的地址. 而这里所指
的环境变量, 通俗一点讲就是在当前shell中, 这些如gcc这一命令是指向哪个文件. 比如你安装了两个
版本的gcc编译器, 你就需要去设置环境变量, 告诉系统当你调用gcc的时候你到底想调用哪个版本的
gcc, 把你想调用的那个gcc的路径和gcc绑定起来. 所以, 当执行上述命令, 得到了编译器地址, 就可
以进行下一步了. 如果没有, 要么是环境变量中没有指定编译器路径, 要么是没有安装编译器, 需自行
判断.

当检查完编译器之后, 去https://www.mpich.org/downloads/ 选择合适的版本下载, 对于没有图形界
面的服务器, 也可使用wget命令下载.  tar命令是解压文件的命令. MPI库通常采用的是源码安装, 因
此, 需要使用cd命令进入到解压后的文件夹中, 使用./configure进行安装前的设置与检查, 由于我们
只需要更改一下安装的路径, 因此在--prefix这一参数中, 设置你想要安装的路径即可. 执行这一行之
后, 就会开始检查编译环境是否满足, 此时报错多半是因为编译器安装的问题或者编译器版本不匹配的
问题, 一般通过安装最新的编译器能解决. 这一步成功完成之后, 即可使用make命令去执行编译. 该路
径下makefile文件已经写好了这些源代码的编译规则, 因此输入make即可开始按照makefile的规则对源
码进行编译. 

如果你做的工作和底层语言如Fortran, C或C++之类的, 
还是有必要学习一下makefile的写法, 有助于之后的多文件编译工作. 
顺便一提, 使用Linux学习底层语言是更有好处的, 
因为Windows初学编程语言通常是使用集成开发环境, 在对代码进行编译时通常是一键操作, 
导致中间的几个过程会被下意识的忽略掉, 这将导致一开始适应不了Linux环境下编译文件的命令. 
当make完成之后, 就可以使用make install命令进行安装了.

```bash
wget http://www.mpich.org/static/downloads/3.3.2/mpich-3.3.2.tar.gz 
tar -zxvf mpich-3.3.2.tar.gz #解压下载的压缩包 
cd mpich-3.3.2 #进入解压后的文件夹内 
./configure  --prefix=/usr/local/mpich-3.3.2 
# --prefix这一参数是设置安装的路径，根据需要设置合适的路径即可，但需要记住安装的位置 
make 
make install 
如果没有报错, 就说明顺利安装完成了.
```

### 环境变量的配置

安装完成后, 可以去之前--prefix设置的路径去看一下安装结果. 安装好了之后, 还需要告诉系统mpi
库的路径地址, 这样当你调用mpi的命令时, 系统才知道你在干什么. 在用户的根目录下, 有一个
.bashrc的文本文件(默认使用的是bash, 如果是zsh等自行查阅资料, 我在这里避免信息过多导致初学
者疑惑). 这个文件可以理解为, 每次打开终端时都会加载的启动项. ~即为家目录, 也就是用户的根目
录.

```bash
vim ~/.bashrc
```

通过vim打开当前用户下所对应的.bashrc文件, 在其中加入一行(建议添加在最下面一行)

```bash
export PATH="/usr/local/mpich-3.3.2/bin:$PATH"
```

保存退出之后 , 使用source这一命令执行一下就把新加的命令执行了. 前面说过, .bashrc文件是每次
开启终端后的类似加载启动项文件. 也就是说, 如果你不想手动source来加载的话, 也可以通过新打开
一个终端让它开启时自动加载.

```bash
source ~/.bashrc 
which mpicc 
which mpif90 
```

之后, 用which来检验下配置的环境变量是否正确. 如果显示了其路径, 则说明安装顺利完成了. 这时
候, 进入到最开始解压的文件夹中, 到解压的文件夹内的examples文件夹中, 测试一下hello是否能顺
利运行.

```bash
mpirun -np 4 ./hello
```

若可运行说明顺利完成安装.  
